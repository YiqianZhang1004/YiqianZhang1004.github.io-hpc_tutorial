[["index.html", "HPC Tutorial in CINEMA CINEMA Research Group", " HPC Tutorial in CINEMA Yiqian Zhang 2024-07-18 CINEMA Research Group The CINEMA (Clinical Informatics, NEuroimaging, and Multiomics Analysis) Group has established itself at CWRU (Case Western Reserve University) as a biostatistical and bioinformatic center of facilitating computational excellence and quantitative innovation for biomedical research since its launch in 2023. We are open to cross-disciplinary collaborations and the practical application of research findings. We provide statistical support to translate large medical data from benchwork to knowledge in precision medicine. "],["getting-started.html", "Chapter 1 Getting Started 1.1 Lab Group Directory 1.2 Key Areas in CWRU HPC OnDemand Web Portal 1.3 Bioinformatics Package Installation Status", " Chapter 1 Getting Started 1.1 Lab Group Directory /mnt/vstor/SOM_PQHS_LXZ716 1.2 Key Areas in CWRU HPC OnDemand Web Portal The following figures provide a visual guide to key areas within the CWRU HPC OnDemand Web Portal that users frequently interact with. Home Directory:The location of the Home Directory in the CWRU HPC OnDemand Web Portal. Active Jobs: Where to view currently running jobs that have been submitted to SLURM. Pioneer Shell Access: Where to access the Pioneer Shell to run your code on the HPC cluster. 1.3 Bioinformatics Package Installation Status This document lists various bioinformatics packages, their installation status, and links to their respective sections. Package Link to Section Installed Woltka Woltka Yes Samtools Samtools Yes Qiime 2 Qiime 2 Yes Kraken2 Kraken2 Yes "],["submitting-batch-jobs.html", "Chapter 2 Submitting Batch Jobs", " Chapter 2 Submitting Batch Jobs When running programs that take a very long time to complete, itâ€™s impractical to wait for them to run on your local machine or cluster interactively. Instead, you can submit these programs as batch jobs to a High-Performance Computing (HPC) cluster. This tutorial will guide you through creating and submitting a SLURM job script to run a batch job on an HPC cluster. We will be using the sbatch command to submit the job. Create a SLURM Job Script: A SLURM job script is a Bash script that contains directives for the SLURM workload manager. These directives specify resources such as the number of nodes, CPU cores, memory, job duration, and more. Below is a sample SLURM job script: YourFileName.slurm: #!/bin/bash #SBATCH -N 3 # Requests 3 node for the job #SBATCH -c 24 # Requests 24 CPU core #SBATCH --mem-per-cpu=128G # Allocates 128 GB of memory per CPU core #SBATCH --time=0-00:15:00 # 15 minutes #SBATCH --output=my.stdout # Directs the standard output to a file named &quot;my.stdout&quot; #SBATCH --error=my.stderr # Directs the standard error to a file named &quot;my.stderr&quot; #SBATCH --mail-user=abac123@case.edu # Specifies the email address to receive job notifications. #SBATCH --mail-type=ALL # Sends email notifications for all events (job start, end, fail, etc.) #SBATCH --job-name=&quot;just_a_test&quot; # Names the job &quot;just_a_test&quot; # Put commands for executing job below this line # example: module load Python python --version Save the Job Script: Save the script with a .slurm extension. For example, save it as YourFileName.slurm. Access the HPC Cluster: Connect to the HPC cluster using cluster/_pioneer Shell Access. Navigate to the Directory Containing Your SLURM Script: Use the cd command to navigate to the directory where you saved YourFileName.slurm. Submit the SLURM Job Script: Use the sbatch command to submit your job script to the SLURM scheduler: sbatch YourFileName.slurm Monitor the Job: You can check the progress of the job in the Job/Active Jobs section. Check Job Output: Once the job completes, check the output file (my.stdout in this example) for the results of your job. If the job failed, you can check the my.stderr file for the reason. "],["conda.html", "Chapter 3 Conda", " Chapter 3 Conda Activate Conda: Run the following command to activate Conda: source /mnt/vstor/SOM_PQHS_LXZ716/software/miniconda3/bin/activate "],["woltka.html", "Chapter 4 Woltka", " Chapter 4 Woltka Woltka Github Link Woltka is a bioinformatics toolkit designed for microbiome studies that processes metagenomic sequencing data to produce taxonomic and functional profiles. It allows researchers to classify reads, aggregate them by various biological or functional units, and perform ecological and comparative analyses, making it useful for understanding microbial community structure and function. Woltka is already installed in the Lab Group Conda environment. Here is the way to access it: Access the HPC Cluster: Connect to the HPC cluster using cluster/_pioneer Shell Access. Activate Conda: Conda is already installed on the HPC. To activate Conda, run the following command: source /mnt/vstor/SOM_PQHS_LXZ716/software/miniconda3/bin/activate Activate the Woltka Environment: To activate the Woltka environment, use the following command: conda activate woltka "],["samtools.html", "Chapter 5 Samtools 5.1 Use Samtools 5.2 Install Samtools", " Chapter 5 Samtools Samtools Website Samtools is a suite of programs used for interacting with high-throughput sequencing data, particularly in the context of microbiome research. It provides essential tools for manipulating and analyzing BAM, SAM, and CRAM files, which are formats for storing large nucleotide sequence alignments. In microbiome studies, Samtools is used to sort, index, and filter alignment data, enabling researchers to efficiently process and analyze metagenomic and metatranscriptomic sequences, assess microbial diversity, and identify microbial taxa and functional genes within complex microbial communities. 5.1 Use Samtools Samtools already installed in group directory, you can just update your path to use samtools by running the following: export PATH=/mnt/vstor/SOM_PQHS_LXZ716/software/Samtools/bin:$PATH To check if Samtools has been successfully installed, you can perform the following steps: samtools --version 5.2 Install Samtools If you want to download and install your own Samtools, follow these steps: Download the Source Code: Download the source code for Samtools from the official website: https://www.htslib.org/download/ Upload to HPC: Upload the downloaded file to your HPC environment. Unzip the File: Once uploaded, unzip the file using the following command: tar -xvjf samtools-1.20.tar.bz2 Change Directory: Navigate to the Samtools directory: cd samtools-1.20 Configure the Installation: Configure the installation by running (replace /where/to/install with your desired installation directory): ./configure --prefix=/where/to/install Compile the Source Code: Compile the source code using: make Install Samtools: Install Samtools by running: make install Update Your PATH: The executable programs will be installed in a bin subdirectory under your specified prefix. Add this directory to your $PATH to access the programs easily (replace /where/to/install with your specified installation directory): export PATH=/where/to/install/bin:$PATH "],["qiime-2.html", "Chapter 6 QIIME 2 6.1 Use QIIME 2 6.2 Available Qiime 2 Databases", " Chapter 6 QIIME 2 QIIME 2 Website Qiime 2 (Quantitative Insights Into Microbial Ecology 2) is a powerful, open-source bioinformatics platform designed for performing microbiome analysis from raw DNA sequencing data. It provides tools for the analysis and interpretation of high-throughput community sequencing data, facilitating tasks such as quality control, taxonomic classification, diversity analysis, and visualization. Qiime 2 supports a modular plugin system, enabling users to integrate various analytical methods and customize workflows, making it an essential tool for researchers studying microbial ecology, diversity, and function. 6.1 Use QIIME 2 Qiime 2 is already installed in the Lab Group Conda environment. To use it, follow these steps: Activate Conda: Run the following command to activate Conda: source /mnt/vstor/SOM_PQHS_LXZ716/software/miniconda3/bin/activate Activate the Qiime 2 Environment: Activate the Qiime 2 environment by running: conda activate qiime2-amplicon-2024.5 Check the Version: Run the following command to check if Qiime 2 is installed and to see the version number: qiime --version 6.2 Available Qiime 2 Databases A pre-trained classifier database for Qiime 2 is available in the Group Directory. This database can be found under the following directory: /mnt/vstor/SOM_PQHS_LXZ716/Reference The available database includes: QIIME2_Pre-trained_Classifier: A pre-trained classifier for taxonomic classification of microbial sequences, optimized for use with Qiime 2. "],["kraken2.html", "Chapter 7 Kraken2 7.1 Use Kraken2 7.2 Available Kraken2 Databases", " Chapter 7 Kraken2 Kraken 2 Manual Kraken2 is a highly efficient, open-source taxonomic classification system designed for metagenomic sequence data. It utilizes exact k-mer matches to classify sequences by comparing them to a database of known genomes, providing accurate and rapid identification of microbial taxa. Kraken2 is widely used in microbiome research for analyzing complex microbial communities, enabling researchers to classify millions of sequences in a matter of minutes. Its performance and accuracy make it a valuable tool for large-scale metagenomic studies, pathogen detection, and environmental microbiology. 7.1 Use Kraken2 Kraken2 is already installed. To copy Kraken2 binaries to your personal bin directory, run the following command: cp /mnt/vstor/SOM_PQHS_LXZ716/software/Kraken2/kraken2{,-build,-inspect} $HOME/bin Check the Version: Run the following command to check if Kraken2 is installed and to see the version number: kraken2 --version 7.2 Available Kraken2 Databases Some Kraken2 databases are available in the Group Directory. These databases can be found under the following directory: /mnt/vstor/SOM_PQHS_LXZ716/Reference The available databases include: kraken_db: A general-purpose database containing a broad range of microbial genomes for taxonomic classification. kraken2_human_db: A specialized database designed to classify human-associated microbiomes, containing genomes relevant to human health. kraken2_bacteria_db: A targeted database focusing specifically on bacterial genomes, useful for detailed bacterial community analysis. "]]
