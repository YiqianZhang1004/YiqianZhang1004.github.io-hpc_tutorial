[["index.html", "HPC Tutorial in CINEMA CINEMA Research Group", " HPC Tutorial in CINEMA Yiqian Zhang 2024-07-19 CINEMA Research Group The CINEMA (Clinical Informatics, NEuroimaging, and Multiomics Analysis) Group has established itself at CWRU (Case Western Reserve University) as a biostatistical and bioinformatic center of facilitating computational excellence and quantitative innovation for biomedical research since its launch in 2023. We are open to cross-disciplinary collaborations and the practical application of research findings. We provide statistical support to translate large medical data from benchwork to knowledge in precision medicine. "],["getting-started.html", "Chapter 1 Getting Started 1.1 Lab Group Directory 1.2 Key Areas in CWRU HPC OnDemand Web Portal 1.3 Bioinformatics Package Installation Status", " Chapter 1 Getting Started 1.1 Lab Group Directory /mnt/vstor/SOM_PQHS_LXZ716 1.2 Key Areas in CWRU HPC OnDemand Web Portal The following figures provide a visual guide to key areas within the CWRU HPC OnDemand Web Portal that users frequently interact with. Home Directory:The location of the Home Directory in the CWRU HPC OnDemand Web Portal. Active Jobs: Where to view currently running jobs that have been submitted to SLURM. Pioneer Shell Access: Where to access the Pioneer Shell to run your code on the HPC cluster. 1.3 Bioinformatics Package Installation Status This document lists various bioinformatics packages, their installation status, and links to their respective sections. Package Link to Section Installed Woltka Woltka Yes Samtools Samtools Yes Qiime 2 Qiime 2 Yes Kraken2 Kraken2 Yes "],["submitting-batch-jobs.html", "Chapter 2 Submitting Batch Jobs", " Chapter 2 Submitting Batch Jobs When running programs that take a very long time to complete, it’s impractical to wait for them to run on your local machine or cluster interactively. Instead, you can submit these programs as batch jobs to a High-Performance Computing (HPC) cluster. This tutorial will guide you through creating and submitting a SLURM job script to run a batch job on an HPC cluster. We will be using the sbatch command to submit the job. Create a SLURM Job Script: A SLURM job script is a Bash script that contains directives for the SLURM workload manager. These directives specify resources such as the number of nodes, CPU cores, memory, job duration, and more. Below is a sample SLURM job script: YourFileName.slurm: #!/bin/bash #SBATCH -N 3 # Requests 3 node for the job #SBATCH -c 24 # Requests 24 CPU core #SBATCH --mem-per-cpu=128G # Allocates 128 GB of memory per CPU core #SBATCH --time=0-00:15:00 # 15 minutes #SBATCH --output=my.stdout # Directs the standard output to a file named &quot;my.stdout&quot; #SBATCH --error=my.stderr # Directs the standard error to a file named &quot;my.stderr&quot; #SBATCH --mail-user=abac123@case.edu # Specifies the email address to receive job notifications. #SBATCH --mail-type=ALL # Sends email notifications for all events (job start, end, fail, etc.) #SBATCH --job-name=&quot;just_a_test&quot; # Names the job &quot;just_a_test&quot; # Put commands for executing job below this line # example: module load Python python --version Save the Job Script: Save the script with a .slurm extension. For example, save it as YourFileName.slurm. Access the HPC Cluster: Connect to the HPC cluster using cluster/_pioneer Shell Access. Navigate to the Directory Containing Your SLURM Script: Use the cd command to navigate to the directory where you saved YourFileName.slurm. Submit the SLURM Job Script: Use the sbatch command to submit your job script to the SLURM scheduler: sbatch YourFileName.slurm Monitor the Job: You can check the progress of the job in the Job/Active Jobs section. Check Job Output: Once the job completes, check the output file (my.stdout in this example) for the results of your job. If the job failed, you can check the my.stderr file for the reason. "],["conda.html", "Chapter 3 Conda", " Chapter 3 Conda Activate Conda: Run the following command to activate Conda: source /mnt/vstor/SOM_PQHS_LXZ716/software/miniconda3/bin/activate "],["woltka.html", "Chapter 4 Woltka", " Chapter 4 Woltka Woltka Github Link Woltka is a bioinformatics toolkit designed for microbiome studies that processes metagenomic sequencing data to produce taxonomic and functional profiles. It allows researchers to classify reads, aggregate them by various biological or functional units, and perform ecological and comparative analyses, making it useful for understanding microbial community structure and function. Woltka is already installed in the Lab Group Conda environment. Here is the way to access it: Access the HPC Cluster: Connect to the HPC cluster using cluster/_pioneer Shell Access. Activate Conda: Conda is already installed on the HPC. To activate Conda, run the following command: source /mnt/vstor/SOM_PQHS_LXZ716/software/miniconda3/bin/activate Activate the Woltka Environment: To activate the Woltka environment, use the following command: conda activate woltka "],["samtools.html", "Chapter 5 Samtools 5.1 Use Samtools 5.2 Install Samtools", " Chapter 5 Samtools Samtools Website Samtools is a suite of programs used for interacting with high-throughput sequencing data, particularly in the context of microbiome research. It provides essential tools for manipulating and analyzing BAM, SAM, and CRAM files, which are formats for storing large nucleotide sequence alignments. In microbiome studies, Samtools is used to sort, index, and filter alignment data, enabling researchers to efficiently process and analyze metagenomic and metatranscriptomic sequences, assess microbial diversity, and identify microbial taxa and functional genes within complex microbial communities. 5.1 Use Samtools Samtools already installed in group directory, you can just update your path to use samtools by running the following: export PATH=/mnt/vstor/SOM_PQHS_LXZ716/software/Samtools/bin:$PATH To check if Samtools has been successfully installed, you can perform the following steps: samtools --version 5.2 Install Samtools If you want to download and install your own Samtools, follow these steps: Download the Source Code: Download the source code for Samtools from the official website: https://www.htslib.org/download/ Upload to HPC: Upload the downloaded file to your HPC environment. Unzip the File: Once uploaded, unzip the file using the following command: tar -xvjf samtools-1.20.tar.bz2 Change Directory: Navigate to the Samtools directory: cd samtools-1.20 Configure the Installation: Configure the installation by running (replace /where/to/install with your desired installation directory): ./configure --prefix=/where/to/install Compile the Source Code: Compile the source code using: make Install Samtools: Install Samtools by running: make install Update Your PATH: The executable programs will be installed in a bin subdirectory under your specified prefix. Add this directory to your $PATH to access the programs easily (replace /where/to/install with your specified installation directory): export PATH=/where/to/install/bin:$PATH "],["qiime-2.html", "Chapter 6 QIIME 2 6.1 Use QIIME 2 6.2 Available Qiime 2 Databases 6.3 Example for Jax.IU.Pitt Microbiome Pilot Study", " Chapter 6 QIIME 2 QIIME 2 Website Qiime 2 (Quantitative Insights Into Microbial Ecology 2) is a powerful, open-source bioinformatics platform designed for performing microbiome analysis from raw DNA sequencing data. It provides tools for the analysis and interpretation of high-throughput community sequencing data, facilitating tasks such as quality control, taxonomic classification, diversity analysis, and visualization. Qiime 2 supports a modular plugin system, enabling users to integrate various analytical methods and customize workflows, making it an essential tool for researchers studying microbial ecology, diversity, and function. 6.1 Use QIIME 2 Qiime 2 is already installed in the Lab Group Conda environment. To use it, follow these steps: Activate Conda: Run the following command to activate Conda: source /mnt/vstor/SOM_PQHS_LXZ716/software/miniconda3/bin/activate Activate the Qiime 2 Environment: Activate the Qiime 2 environment by running: conda activate qiime2-amplicon-2024.5 Check the Version: Run the following command to check if Qiime 2 is installed and to see the version number: qiime --version 6.2 Available Qiime 2 Databases A pre-trained classifier database for Qiime 2 is available in the Group Directory. This database can be found under the following directory: /mnt/vstor/SOM_PQHS_LXZ716/Reference The available database includes: QIIME2_Pre-trained_Classifier: A pre-trained classifier for taxonomic classification of microbial sequences, optimized for use with Qiime 2. 6.3 Example for Jax.IU.Pitt Microbiome Pilot Study 6.3.1 Importing Data Fastq Manifest Formats When importing data, we use the “Fastq manifest” format. This method is suitable for data that do not fit the common multiplexed or demultiplexed formats (e.g., EMP or Casava). To import your data manually, you will need to create a manifest file and use the qiime tools import command. Format Description First, you’ll create a text file called a “manifest file”, which maps sample identifiers to fastq.gz or fastq absolute filepaths that contain sequence and quality data for the sample (i.e., these are FASTQ files). The manifest file also indicates the direction of the reads in each fastq.gz or fastq file. The manifest file is designed to be a simple format that doesn’t put restrictions on the naming of the demultiplexed fastq.gz / fastq files. The manifest file is a tab-separated (i.e., .tsv) text file. The first column defines the Sample ID, while the second (and optional third) column defines the absolute filepath to the forward (and optional reverse) reads. The fastq.gz absolute filepaths may contain environment variables (e.g., $HOME or $PWD). Example Manifest File for Paired-End Reads Here is an example of a manifest file for paired-end read data: sample-id forward-absolute-filepath reverse-absolute-filepath 288593663 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288593663_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288593663_R2.fastq.gz 288601191 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288601191_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288601191_R2.fastq.gz 288605432 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288605432_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288605432_R2.fastq.gz 288613647 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288613647_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288613647_R2.fastq.gz 288625970 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288625970_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288625970_R2.fastq.gz 288638583 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288638583_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288638583_R2.fastq.gz 288638603 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288638603_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288638603_R2.fastq.gz 288658590 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288658590_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288658590_R2.fastq.gz 288662694 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288662694_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288662694_R2.fastq.gz 288696281 /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288696281_R1.fastq.gz /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/288696281_R2.fastq.gz Importing the Data Use the following command to import the data into QIIME 2: qiime tools import \\ --type &#39;SampleData[PairedEndSequencesWithQuality]&#39; \\ --input-path /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/manifest.tsv \\ --output-path /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/paired-end-demux.qza \\ --input-format PairedEndFastqManifestPhred33V2 For more information on importing data and using different formats, refer to the QIIME 2 Importing Tutorial. 6.3.2 Summarizing Demultiplexed Sequences Before denoising, it is important to visualize the quality of the sequencing data. This step summarizes the demultiplexed sequences and generates a visualization to help determine the optimal truncation lengths for denoising. qiime demux summarize \\ --i-data /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/paired-end-demux.qza \\ --o-visualization /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/demux-summary.qzv --i-data: Input file with demultiplexed sequences. --o-visualization: Output file for the summary visualization. The output visualization (demux-summary.qzv) provides interactive plots of the quality scores across all sequences. This information is crucial for determining the appropriate truncation lengths (--p-trunc-len-f and --p-trunc-len-r) to use in the denoising step. How to Choose Truncation Lengths: Open the Visualization: Open the demux-summary.qzv file in QIIME 2 View QIIME 2 View. Inspect the Quality Plots: Look at the interactive quality plots for the forward and reverse reads. Each plot shows the distribution of quality scores across all positions in your reads. Identify Quality Drop-off Points: Identify the position in the reads where the quality scores start to drop significantly. This is usually seen as a downward trend in the quality scores towards the end of the reads. For example, if the quality scores drop below a threshold (e.g., Q30) around position 230 for the forward reads and position 170 for the reverse reads, these positions might be suitable truncation points. Choose Conservative Truncation Lengths: To ensure high-quality data, choose truncation lengths that are slightly before the quality scores drop significantly. This helps to retain more high-quality bases. In this example, you might choose –p-trunc-len-f 230 for the forward reads and –p-trunc-len-r 170 for the reverse reads. 6.3.3 Denoising Sequences with DADA2 This step removes noise from the sequencing data, corrects errors, and generates a table of feature abundances (ASVs), representative sequences, and denoising statistics. qiime dada2 denoise-paired \\ --i-demultiplexed-seqs /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/paired-end-demux.qza \\ --p-trim-left-f 0 \\ --p-trim-left-r 0 \\ --p-trunc-len-f 230 \\ --p-trunc-len-r 170 \\ --o-table /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/table.qza \\ --o-representative-sequences /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/rep-seqs.qza \\ --o-denoising-stats /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/denoising-stats.qza --i-demultiplexed-seqs: Input file with demultiplexed sequences. --p-trim-left-f and --p-trim-left-r: Number of bases to trim from the start of each read. --p-trunc-len-f and --p-trunc-len-r: Position at which reads are truncated due to decrease in quality. --o-table: Output file for the feature table (ASVs). --o-representative-sequences: Output file for the representative sequences. --o-denoising-stats: Output file for denoising statistics. 6.3.4 Taxonomic Classification This step classifies the representative sequences into taxonomic groups using a pre-trained classifier. qiime feature-classifier classify-sklearn \\ --i-classifier /mnt/vstor/SOM_PQHS_LXZ716/Reference/QIIME2_Pre-trained_Classifier/silva-138-99-nb-classifier.qza \\ --i-reads /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/rep-seqs.qza \\ --o-classification /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/taxonomy.qza --i-classifier: Pre-trained classifier file. --i-reads: Input file with representative sequences. --o-classification: Output file with taxonomic classification results. 6.3.5 Metadata Visualization This step creates a visualization of the taxonomic classification results, allowing you to review the taxonomy assignments. qiime metadata tabulate \\ --m-input-file /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/taxonomy.qza \\ --o-visualization /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/taxonomy.qzv --m-input-file: Input file with metadata to be visualized. --o-visualization: Output file for the visualization. 6.3.6 Feature Table Summary This step summarizes the feature table, providing an overview of feature counts per sample and other summary statistics. qiime feature-table summarize \\ --i-table /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/table.qza \\ --o-visualization /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/table.qzv \\ --m-sample-metadata-file /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/processed_metadata.tsv --i-table: Input feature table file. --o-visualization: Output file for the summary visualization. --m-sample-metadata-file: Metadata file associated with the samples. 6.3.7 Phylogenetic Tree Construction This step aligns the sequences, masks the alignment to remove highly variable positions, and constructs a phylogenetic tree for diversity analyses. qiime phylogeny align-to-tree-mafft-fasttree \\ --i-sequences /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/rep-seqs.qza \\ --o-alignment /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/aligned-rep-seqs.qza \\ --o-masked-alignment /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/masked-aligned-rep-seqs.qza \\ --o-tree /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/unrooted-tree.qza \\ --o-rooted-tree /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/rooted-tree.qza --i-sequences: Input file with representative sequences. --o-alignment: Output file for aligned sequences. --o-masked-alignment: Output file for masked alignment. --o-tree: Output file for unrooted phylogenetic tree. --o-rooted-tree: Output file for rooted phylogenetic tree. 6.3.8 Taxa Bar Plot Visualization This step creates a bar plot to visualize the taxonomic composition of the samples, providing insights into the relative abundance of different taxa. qiime taxa barplot \\ --i-table /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/table.qza \\ --i-taxonomy /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/taxonomy.qza \\ --m-metadata-file /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/processed_metadata.tsv \\ --o-visualization /mnt/vstor/SOM_PQHS_LXZ716/MicroB2/Analysis_QIIME2/taxa-bar-plots.qzv --i-table: Input feature table file. --i-taxonomy: Input file with taxonomic classification. --m-metadata-file: Metadata file associated with the samples. --o-visualization: Output file for the bar plot visualization. "],["kraken2.html", "Chapter 7 Kraken2 7.1 Use Kraken2 7.2 Available Kraken2 Databases", " Chapter 7 Kraken2 Kraken 2 Manual Kraken2 is a highly efficient, open-source taxonomic classification system designed for metagenomic sequence data. It utilizes exact k-mer matches to classify sequences by comparing them to a database of known genomes, providing accurate and rapid identification of microbial taxa. Kraken2 is widely used in microbiome research for analyzing complex microbial communities, enabling researchers to classify millions of sequences in a matter of minutes. Its performance and accuracy make it a valuable tool for large-scale metagenomic studies, pathogen detection, and environmental microbiology. 7.1 Use Kraken2 Kraken2 is already installed. To copy Kraken2 binaries to your personal bin directory, run the following command: cp /mnt/vstor/SOM_PQHS_LXZ716/software/Kraken2/kraken2{,-build,-inspect} $HOME/bin Check the Version: Run the following command to check if Kraken2 is installed and to see the version number: kraken2 --version 7.2 Available Kraken2 Databases Some Kraken2 databases are available in the Group Directory. These databases can be found under the following directory: /mnt/vstor/SOM_PQHS_LXZ716/Reference The available databases include: kraken_db: A general-purpose database containing a broad range of microbial genomes for taxonomic classification. kraken2_human_db: A specialized database designed to classify human-associated microbiomes, containing genomes relevant to human health. kraken2_bacteria_db: A targeted database focusing specifically on bacterial genomes, useful for detailed bacterial community analysis. "]]
